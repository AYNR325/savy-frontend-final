
// import { useState, useEffect, useRef } from "react";
// import { useNavigate } from "react-router-dom";
// import { ArrowLeft, Search } from "lucide-react";

// function ObjectFinder() {
//   const [stream, setStream] = useState(null);
//   const [detections, setDetections] = useState([]);
//   const [lastDetections, setLastDetections] = useState([]);
//   const [objectToFind, setObjectToFind] = useState("");
//   const [isCapturing, setIsCapturing] = useState(false);
//   const [message, setMessage] = useState("");
//   const [isSpeaking, setIsSpeaking] = useState(false);
//   const videoRef = useRef(null);
//   const canvasRef = useRef(null);
//   const navigate = useNavigate();

//   useEffect(() => {
//     async function startCamera() {
//       try {
//         const videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
//         setStream(videoStream);
//       } catch (error) {
//         console.error("Error starting camera:", error);
//       }
//     }
//     startCamera();
//   }, []);

//   useEffect(() => {
//     if (stream && videoRef.current) {
//       videoRef.current.srcObject = stream;
//     }
//   }, [stream]);

//   useEffect(() => {
//     if (!isCapturing) return;
//     const interval = setInterval(captureFrame, 1000);
//     return () => clearInterval(interval);
//   }, [isCapturing]);

//   const captureFrame = async () => {
//     if (!videoRef.current || !canvasRef.current) return;

//     const video = videoRef.current;
//     const canvas = canvasRef.current;
//     const ctx = canvas.getContext("2d");

//     canvas.width = video.videoWidth;
//     canvas.height = video.videoHeight;
//     ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

//     const imageData = canvas.toDataURL("image/jpeg");
//     sendToBackend(imageData);
//   };

//   const sendToBackend = async (imageData) => {
//     try {
//       const response = await fetch("http://127.0.0.1:5000/detect", {
//         method: "POST",
//         headers: { "Content-Type": "application/json" },
//         body: JSON.stringify({ image: imageData.split(",")[1], object: objectToFind }),
//       });

//       const result = await response.json();
//       if (result.detections && result.detections.length > 0) {
//         setDetections(result.detections);
//         setLastDetections(result.detections);
//         setMessage("");
//         drawBoundingBox(result.detections);
//         speakNavigation(result.detections[0].navigation);
//       } else {
//         setDetections([]);
//         setMessage(`No ${objectToFind} detected.`);
//       }
//     } catch (error) {
//       console.error("Error sending image to backend:", error);
//       setMessage("Error connecting to backend.");
//     }
//   };

//   const drawBoundingBox = (detections) => {
//     if (!canvasRef.current || !videoRef.current) return;

//     const canvas = canvasRef.current;
//     const ctx = canvas.getContext("2d");

//     canvas.width = videoRef.current.videoWidth;
//     canvas.height = videoRef.current.videoHeight;

//     ctx.clearRect(0, 0, canvas.width, canvas.height);

//     detections.forEach((det) => {
//       const [x1, y1, x2, y2] = det.bbox;
//       ctx.strokeStyle = "lime";
//       ctx.lineWidth = 3;
//       ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
//       ctx.fillStyle = "lime";
//       ctx.font = "16px Arial";
//       ctx.fillText(det.label || "Unknown", x1, y1 - 5);
//     });
//   };

//   const speakNavigation = (text) => {
//     if (!text || isSpeaking) return;
//     const utterance = new SpeechSynthesisUtterance(text);
//     utterance.onstart = () => setIsSpeaking(true);
//     utterance.onend = () => setIsSpeaking(false);
//     window.speechSynthesis.speak(utterance);
//   };

//   const handleStartDetection = () => {
//     if (objectToFind.trim()) {
//       setIsCapturing(true);
//       setMessage("");
//       setDetections([]);
//     } else {
//       alert("Please enter an object to find.");
//     }
//   };

//   const handleVoiceSearch = () => {
//     const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
//     recognition.lang = 'en-US';
//     recognition.onresult = (event) => {
//       const object = event.results[0][0].transcript;
//       setObjectToFind(object);
//       handleStartDetection();
//     };
//     recognition.start();
//   };

//   return (
//     <div style={{
//       minHeight: "100vh",
//       color: "white",
//       padding: "20px"
//     }}>
//       {/* Back Button */}
//       <button
//   onClick={() => navigate(-1)}
//   style={{
//     position: "fixed", // <-- fixed to screen
//     top: "20px",
//     left: "20px",
//     backgroundColor: "#00f2a9",
//     color: "black",
//     border: "none",
//     padding: "8px 14px",
//     borderRadius: "10px",
//     fontWeight: "bold",
//     display: "flex",
//     alignItems: "center",
//     gap: "6px",
//     width: "fit-content",
//     zIndex: 1000 // stays above other content
//   }}
// >
//   <ArrowLeft size={20} /> Back
// </button>


//       <div style={{ display: "flex", flexDirection: "column", alignItems: "center", gap: "20px" }}>
//         <div style={{ position: "relative" }}>
//           <video ref={videoRef} autoPlay playsInline style={{ width: "100%", maxWidth: "500px", borderRadius: "15px", border: "2px solid #00f2a9" }} />
//           <canvas ref={canvasRef} style={{ position: "absolute", top: 0, left: 0, width: "100%", maxWidth: "500px" }} />
//         </div>

//         <input
//           type="text"
//           value={objectToFind}
//           onChange={(e) => setObjectToFind(e.target.value)}
//           placeholder="Enter object to find"
//           style={{ padding: "10px", borderRadius: "10px", width: "300px", border: "2px solid #00f2a9", backgroundColor: "#001f3f", color: "white" }}
//         />

//         <div style={{ display: "flex", gap: "20px", flexWrap: "wrap" }}>
//           <button onClick={handleStartDetection} style={buttonStyle}>
//             ğŸ” Start Detection
//           </button>
//           <button onClick={handleVoiceSearch} style={buttonStyle}>
//             ğŸ¤ Voice Search
//           </button>
//         </div>

//         {message && (
//           <div style={{ backgroundColor: "#ff5555", padding: "10px 20px", borderRadius: "10px" }}>
//             <strong>{message}</strong>
//           </div>
//         )}

//         {lastDetections.length > 0 && (
//           <div style={{ backgroundColor: "#0066ff", padding: "15px 20px", borderRadius: "10px", marginTop: "10px" }}>
//             <h3 style={{ marginBottom: "10px" }}>Navigation:</h3>
//             <p>{lastDetections[0].navigation}</p>
//           </div>
//         )}
//       </div>
//     </div>
//   );
// }

// const buttonStyle = {
//   padding: "15px 30px",
//   backgroundColor: "#00f2a9",
//   color: "black",
//   fontWeight: "bold",
//   borderRadius: "12px",
//   border: "none",
//   cursor: "pointer",
//   fontSize: "16px"
// };

// export default ObjectFinder;

//new
import { useState, useEffect, useRef } from "react";
import { useNavigate } from "react-router-dom";
import { ArrowLeft } from "lucide-react";

function ObjectFinder() {
Â  const navigate = useNavigate();

Â  const [stream, setStream] = useState(null);
Â  const [detections, setDetections] = useState([]);
Â  const [lastDetections, setLastDetections] = useState([]);
Â  const [objectToFind, setObjectToFind] = useState("");
Â  const [isCapturing, setIsCapturing] = useState(false);
Â  const [message, setMessage] = useState("");
Â  const [noObjectTimer, setNoObjectTimer] = useState(null);
Â  const [hasDetectedOnce, setHasDetectedOnce] = useState(false);
Â  const [isSpeaking, setIsSpeaking] = useState(false);

Â  const [videoDevices, setVideoDevices] = useState([]);
Â  const [currentDeviceIndex, setCurrentDeviceIndex] = useState(0);

Â  const videoRef = useRef(null);
Â  const canvasRef = useRef(null);

const [isLoading, setIsLoading] = useState(false);


Â  const startCamera = async (deviceId = null) => {
Â  Â  try {
Â  Â  Â  const constraints = {
Â  Â  Â  Â  video: deviceId ? { deviceId: { exact: deviceId } } : { facingMode: "environment" },
Â  Â  Â  };
Â  Â  Â  const videoStream = await navigator.mediaDevices.getUserMedia(constraints);
Â  Â  Â  setStream(videoStream);
Â  Â  } catch (error) {
Â  Â  Â  console.error("Error accessing camera:", error);
Â  Â  }
Â  };

Â  const switchCamera = () => {
Â  Â  if (videoDevices.length < 2) {
Â  Â  Â  alert("No secondary camera found.");
Â  Â  Â  return;
Â  Â  }
Â  Â  const nextIndex = (currentDeviceIndex + 1) % videoDevices.length;
Â  Â  setCurrentDeviceIndex(nextIndex);
Â  Â  if (stream) {
Â  Â  Â  stream.getTracks().forEach((track) => track.stop());
Â  Â  }
Â  Â  startCamera(videoDevices[nextIndex].deviceId);
Â  };

Â  useEffect(() => {
Â  Â  const getDevices = async () => {
Â  Â  Â  const devices = await navigator.mediaDevices.enumerateDevices();
Â  Â  Â  const videoInputs = devices.filter((d) => d.kind === "videoinput");
Â  Â  Â  setVideoDevices(videoInputs);
Â  Â  Â  startCamera(videoInputs[0]?.deviceId);
Â  Â  };
Â  Â  getDevices();
Â  }, []);

Â  useEffect(() => {
Â  Â  if (stream && videoRef.current) {
Â  Â  Â  videoRef.current.srcObject = stream;
Â  Â  }
Â  }, [stream]);

Â  useEffect(() => {
Â  Â  if (!isCapturing) return;
Â  Â  const interval = setInterval(captureFrame, 10000);
Â  Â  return () => clearInterval(interval);
Â  }, [isCapturing, objectToFind]);

Â  const captureFrame = () => {
Â  Â  const video = videoRef.current;
Â  Â  const canvas = canvasRef.current;
Â  Â  if (!video || !canvas) return;

Â  Â  const ctx = canvas.getContext("2d");
Â  Â  canvas.width = video.videoWidth;
Â  Â  canvas.height = video.videoHeight;
Â  Â  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

Â  Â  canvas.toBlob(blob => {
Â  Â  Â  if (blob) sendToBackend(blob);
Â  Â  Â  else console.error("Failed to create blob from canvas.");
Â  Â  }, "image/jpeg", 0.8);
Â  };

Â  const sendToBackend = async (imageBlob) => {
Â  Â  try {
    setIsLoading(true);
Â  Â  Â  const formData = new FormData();
Â  Â  Â  formData.append("image", imageBlob, "frame.jpg");
Â  Â  Â  formData.append("object", objectToFind.toLowerCase().trim());

Â  Â  Â  const response = await fetch("https://object-finder-final.onrender.com/detect", {
Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  body: formData,
Â  Â  Â  });

Â  Â  Â  if (response.status === 404) {
Â  Â  Â  Â  if (!hasDetectedOnce && !noObjectTimer) {
Â  Â  Â  Â  Â  const timer = setTimeout(() => {
Â  Â  Â  Â  Â  Â  setMessage(`No ${objectToFind} detected.`);
Â  Â  Â  Â  Â  Â  setNoObjectTimer(null);
Â  Â  Â  Â  Â  }, 30000);
Â  Â  Â  Â  Â  setNoObjectTimer(timer);
Â  Â  Â  Â  }
Â  Â  Â  Â  setDetections([]);
Â  Â  Â  Â  return;
Â  Â  Â  }

Â  Â  Â  const result = await response.json();
Â  Â  Â  if (result.detections?.length > 0) {
    setIsLoading(false);
Â  Â  Â  Â  setDetections(result.detections);
Â  Â  Â  Â  setLastDetections(result.detections);
Â  Â  Â  Â  setMessage("");
Â  Â  Â  Â  setHasDetectedOnce(true);
Â  Â  Â  Â  drawBoundingBox(result.detections);
Â  Â  Â  Â  playBuzzer();
Â  Â  Â  Â  speakNavigation(result.detections[0].navigation);
Â  Â  Â  Â  if (noObjectTimer) {
Â  Â  Â  Â  Â  clearTimeout(noObjectTimer);
Â  Â  Â  Â  Â  setNoObjectTimer(null);
Â  Â  Â  Â  }
Â  Â  Â  } else {
Â  Â  Â  Â  setDetections([]);
Â  Â  Â  }
Â  Â  } catch (error) {
Â  Â  Â  console.error("Error communicating with backend:", error);
Â  Â  Â  setMessage("Error connecting to backend.");
Â  Â  }
Â  };

Â  const drawBoundingBox = (detections) => {
Â  Â  const canvas = canvasRef.current;
Â  Â  const video = videoRef.current;
Â  Â  if (!canvas || !video) return;

Â  Â  const ctx = canvas.getContext("2d");
Â  Â  canvas.width = video.videoWidth;
Â  Â  canvas.height = video.videoHeight;
Â  Â  ctx.clearRect(0, 0, canvas.width, canvas.height);

Â  Â  detections.forEach(({ bbox, label = "Unknown" }) => {
Â  Â  Â  const [x1, y1, x2, y2] = bbox;
Â  Â  Â  ctx.strokeStyle = "red";
Â  Â  Â  ctx.lineWidth = 3;
Â  Â  Â  ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
Â  Â  Â  ctx.fillStyle = "red";
Â  Â  Â  ctx.font = "16px Arial";
Â  Â  Â  ctx.fillText(label, x1, y1 - 5);
Â  Â  });
Â  };

Â  const playBuzzer = () => {
Â  Â  const audio = new Audio("/alert-33762.mp3");
Â  Â  audio.play().catch(err => console.error("Audio playback failed:", err));
Â  Â  setTimeout(() => {
Â  Â  Â  audio.pause();
Â  Â  Â  audio.currentTime = 0;
Â  Â  }, 10000);
Â  };

Â  const speakNavigation = (text) => {
Â  Â  if (!text || isSpeaking) return;
Â  Â  const utterance = new SpeechSynthesisUtterance(text);
Â  Â  utterance.onstart = () => setIsSpeaking(true);
Â  Â  utterance.onend = () => setIsSpeaking(false);
Â  Â  window.speechSynthesis.speak(utterance);
Â  };

Â  // VOICE LISTENING
Â  useEffect(() => {
Â  Â  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
Â  Â  if (!SpeechRecognition) {
Â  Â  Â  alert("Speech Recognition is not supported in your browser.");
Â  Â  Â  return;
Â  Â  }

Â  Â  const recognition = new SpeechRecognition();
Â  Â  recognition.continuous = false;
Â  Â  recognition.lang = "en-US";

Â  Â  recognition.onstart = () => {
Â  Â  Â  console.log("Voice recognition started");
Â  Â  Â  setMessage("Listening... Please say the object name or say 'switch camera'");
Â  Â  };

Â  Â  recognition.onresult = (event) => {
Â  Â  Â  const spokenText = event.results[0][0].transcript.toLowerCase().trim();
Â  Â  Â  console.log("Recognized command:", spokenText);

Â  Â  Â  if (spokenText.includes("switch camera")) {
Â  Â  Â  Â  switchCamera();
Â  Â  Â  Â  setMessage("Switching camera...");
Â  Â  Â  } else {
Â  Â  Â  Â  setObjectToFind(spokenText);
Â  Â  Â  Â  setIsCapturing(true);
Â  Â  Â  Â  setMessage("");
Â  Â  Â  }
Â  Â  };

Â  Â  recognition.onerror = (event) => {
Â  Â  Â  console.error("Speech recognition error:", event.error);
Â  Â  Â  setMessage("Speech recognition error. Try again.");
Â  Â  };

Â  Â  recognition.onend = () => {
Â  Â  Â  console.log("Voice recognition ended");
Â  Â  };

Â  Â  recognition.start();
Â  }, []);

Â  return (
Â  Â  <div
Â  Â  Â  style={{
Â  Â  Â  Â  display: "flex",
Â  Â  Â  Â  flexDirection: "column",
Â  Â  Â  Â  alignItems: "center",
Â  Â  Â  Â  gap: "20px",
Â  Â  Â  Â  padding: "20px",
Â  Â  Â  Â  minHeight: "100vh",
Â  Â  Â  }}
Â  Â  >
Â  Â  Â  <button
Â  Â  Â  Â  onClick={() => navigate("/camera")}
Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  position: "fixed",
Â  Â  Â  Â  Â  top: "20px",
Â  Â  Â  Â  Â  left: "20px",
Â  Â  Â  Â  Â  backgroundColor: "#00f2a9",
Â  Â  Â  Â  Â  color: "black",
Â  Â  Â  Â  Â  border: "none",
Â  Â  Â  Â  Â  padding: "8px 14px",
Â  Â  Â  Â  Â  borderRadius: "10px",
Â  Â  Â  Â  Â  fontWeight: "bold",
Â  Â  Â  Â  Â  display: "flex",
Â  Â  Â  Â  Â  alignItems: "center",
Â  Â  Â  Â  Â  gap: "6px",
Â  Â  Â  Â  Â  width: "fit-content",
Â  Â  Â  Â  Â  zIndex: 1000,
Â  Â  Â  Â  }}
Â  Â  Â  >
Â  Â  Â  Â  <ArrowLeft size={20} />
Â  Â  Â  </button>

Â  Â  Â  <button
Â  Â  Â  Â  onClick={switchCamera}
Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  backgroundColor: "#007BFF",
Â  Â  Â  Â  Â  color: "white",
Â  Â  Â  Â  Â  border: "none",
Â  Â  Â  Â  Â  padding: "10px 20px",
Â  Â  Â  Â  Â  borderRadius: "10px",
Â  Â  Â  Â  Â  fontWeight: "bold",
          width: "fit-content",
Â  Â  Â  Â  Â  cursor: "pointer",
Â  Â  Â  Â  }}
Â  Â  Â  >
Â  Â  Â  Â  ğŸ”„ Switch Camera
Â  Â  Â  </button>

<button
Â  onClick={() => {
Â  Â  if (objectToFind.trim() !== "") {
Â  Â  Â  setIsCapturing(true);
Â  Â  Â  setMessage("");
Â  Â  }
Â  }}
Â  style={{
Â  Â  marginTop: "10px",
Â  Â  padding: "10px 20px",
Â  Â  backgroundColor: "#1EFFB2",
Â  Â  color: "#001f3f",
Â  Â  border: "none",
Â  Â  borderRadius: "10px",
Â  Â  fontWeight: "bold",
Â  Â  width: "fit-content",
Â  Â  cursor: "pointer",
Â  }}
>
Â  ğŸ” Start Detection
</button>


Â  Â  Â  <p style={{ color: "#1EFFB2", fontWeight: "bold" }}>
Â  Â  Â  Â  Current Camera: {videoDevices[currentDeviceIndex]?.label || "Default"}
Â  Â  Â  </p>

Â  Â  Â  <div
Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  position: "relative",
Â  Â  Â  Â  Â  border: "3px solid #1EFFB2",
Â  Â  Â  Â  Â  borderRadius: "15px",
Â  Â  Â  Â  Â  boxShadow: "0 0 15px #1EFFB2",
Â  Â  Â  Â  Â  overflow: "hidden",
Â  Â  Â  Â  Â  maxWidth: "500px",
Â  Â  Â  Â  Â  width: "100%",
Â  Â  Â  Â  }}
Â  Â  Â  >
Â  Â  Â  Â  <video
Â  Â  Â  Â  Â  ref={videoRef}
Â  Â  Â  Â  Â  autoPlay
Â  Â  Â  Â  Â  playsInline
Â  Â  Â  Â  Â  style={{ width: "100%", height: "auto" }}
Â  Â  Â  Â  />
Â  Â  Â  Â  <canvas
Â  Â  Â  Â  Â  ref={canvasRef}
Â  Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  Â  position: "absolute",
Â  Â  Â  Â  Â  Â  top: 0,
Â  Â  Â  Â  Â  Â  left: 0,
Â  Â  Â  Â  Â  Â  width: "100%",
Â  Â  Â  Â  Â  Â  height: "100%",
Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  />
Â  Â  Â  </div>

Â  Â  Â  <input
Â  Â  Â  Â  type="text"
Â  Â  Â  Â  value={objectToFind}
Â  Â  Â  Â  onChange={(e) => setObjectToFind(e.target.value)}
Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  padding: "12px",
Â  Â  Â  Â  Â  border: "2px solid #1EFFB2",
Â  Â  Â  Â  Â  borderRadius: "10px",
Â  Â  Â  Â  Â  width: "300px",
Â  Â  Â  Â  Â  backgroundColor: "#001f3f",
Â  Â  Â  Â  Â  color: "#1EFFB2",
Â  Â  Â  Â  Â  fontWeight: "bold",
Â  Â  Â  Â  Â  textAlign: "center",
Â  Â  Â  Â  }}
Â  Â  Â  Â  placeholder="Say or enter object to find"
Â  Â  Â  />

Â  Â  Â  {!hasDetectedOnce && message && (
Â  Â  Â  Â  <div
Â  Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  Â  marginTop: "20px",
Â  Â  Â  Â  Â  Â  padding: "15px",
Â  Â  Â  Â  Â  Â  backgroundColor: "#ffcccc",
Â  Â  Â  Â  Â  Â  borderRadius: "10px",
Â  Â  Â  Â  Â  Â  textAlign: "center",
Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  >
Â  Â  Â  Â  Â  <p style={{ fontSize: "16px", fontWeight: "bold", color: "#cc0000" }}>
Â  Â  Â  Â  Â  Â  {message}
Â  Â  Â  Â  Â  </p>
Â  Â  Â  Â  </div>
Â  Â  Â  )}

<style>
        {`
          @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
          }
        `}
      </style>
{isLoading && (
  <div
    style={{
      marginTop: "20px",
      display: "flex",
      justifyContent: "center",
      alignItems: "center",
    }}
  >
    <div style={{
          border: '6px solid #f3f3f3',
          borderTop: '6px solid #1EFFB2',
          borderRadius: '50%',
          width: '40px',
          height: '40px',
          animation: 'spin 0.8s linear infinite'
        }}></div>
  </div>
)}


Â  Â  Â  {lastDetections.length > 0 && (
Â  Â  Â  Â  <div
Â  Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  Â  marginTop: "20px",
Â  Â  Â  Â  Â  Â  padding: "15px",
Â  Â  Â  Â  Â  Â  backgroundColor: "#1EFFB2",
Â  Â  Â  Â  Â  Â  borderRadius: "10px",
Â  Â  Â  Â  Â  Â  textAlign: "center",
Â  Â  Â  Â  Â  Â  color: "#003366",
Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  >
Â  Â  Â  Â  Â  <h2 style={{ fontSize: "18px", fontWeight: "bold" }}>Navigation:</h2>
Â  Â  Â  Â  Â  <p>{lastDetections[0].navigation}</p>
Â  Â  Â  Â  </div>
Â  Â  Â  )}
Â  Â  </div>
Â  );
}

export default ObjectFinder;